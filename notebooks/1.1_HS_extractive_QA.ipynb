{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aaeb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pprint import pprint\n",
    "\n",
    "from haystack.nodes import TextConverter, PDFToTextConverter, DocxToTextConverter, PreProcessor, TfidfRetriever, EmbeddingRetriever\n",
    "from haystack.utils import convert_files_to_docs, print_answers\n",
    "from haystack.document_stores import InMemoryDocumentStore, FAISSDocumentStore\n",
    "from haystack.nodes import FARMReader, TransformersReader\n",
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b11753",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
    "logging.getLogger(\"haystack\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9611de1e",
   "metadata": {},
   "source": [
    "## get PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cc5316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter = TextConverter(remove_numeric_tables=True, valid_languages=[\"en\"])\n",
    "# doc_txt = converter.convert(file_path=\"data/tutorial8/classics.txt\", meta=None)[0]\n",
    "\n",
    "# converter = DocxToTextConverter(remove_numeric_tables=False, valid_languages=[\"en\"])\n",
    "# doc_docx = converter.convert(file_path=\"data/tutorial8/heavy_metal.docx\", meta=None)[0]\n",
    "\n",
    "converter = PDFToTextConverter(remove_numeric_tables=True, valid_languages=[\"en\"])\n",
    "doc_pdf = converter.convert(file_path=\"/data/kg_pdfs_test/dt-csm-solution-brief.pdf\", meta=None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a791d4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b714a9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDFS_PATH=\"/data/kg_pdfs_test/\"\n",
    "\n",
    "all_docs = convert_files_to_docs(dir_path=PDFS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717f5859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "813fc1a9",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82d7b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = PreProcessor(\n",
    "    clean_empty_lines=True,\n",
    "    clean_whitespace=True,\n",
    "    clean_header_footer=False,\n",
    "    split_by=\"word\",\n",
    "    split_length=128,  # smaller splits works better? \n",
    "    split_respect_sentence_boundary=True,\n",
    ")\n",
    "\n",
    "all_docs_process = preprocessor.process(all_docs)\n",
    "\n",
    "print(f\"n_files_input: {len(all_docs)}\\nn_docs_output: {len(all_docs_process)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da29fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs_process[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b15ef00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4ba3e64",
   "metadata": {},
   "source": [
    "## Document Store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c491b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-Memory Document Store\n",
    "# document_store = InMemoryDocumentStore()\n",
    "\n",
    "\n",
    "# The FAISSDocumentStore uses a SQL(SQLite in-memory be default) database under-the-hood to store the document text and other meta data. \n",
    "# The vector embeddings of the text are indexed on a FAISS Index that later is queried for searching answers.\n",
    "document_store = FAISSDocumentStore(faiss_index_factory_str=\"Flat\", similarity=\"dot_product\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a47898",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.write_documents(all_docs_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead82930",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.get_document_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5d4c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4516d47",
   "metadata": {},
   "source": [
    "## Retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77bddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An in-memory TfidfRetriever based on Pandas dataframes\n",
    "\n",
    "tfidf_ret = TfidfRetriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94111ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence BERT embeddings retriever\n",
    "SENT_TRANS_MODEL = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "\n",
    "embedd_ret = EmbeddingRetriever(\n",
    "    document_store=document_store,\n",
    "    embedding_model=SENT_TRANS_MODEL,\n",
    "    model_format=\"sentence_transformers\",\n",
    ")\n",
    "\n",
    "# Important:\n",
    "# Now that we initialized the Retriever, we need to call update_embeddings() to iterate over all previously indexed documents \n",
    "# and update their embedding representation.\n",
    "# While this can be a time consuming operation (depending on the corpus size), it only needs to be done once.\n",
    "# At query time, we only need to embed the query and compare it to the existing document embeddings, which is very fast.\n",
    "\n",
    "document_store.update_embeddings(embedd_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747f2f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.get_all_documents()[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a07676",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is streaming data?\"\n",
    "query1 = \"How is deep learning used in industry?\"\n",
    "query2 = \"What is a data mesh?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c8164",
   "metadata": {},
   "source": [
    "**tfidf retriever:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6790fb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(tfidf_ret.retrieve(query2, top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5780e460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd8cee86",
   "metadata": {},
   "source": [
    "**embeddings retriever:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d191c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(embedd_ret.retrieve(query2, top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd764ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96853cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05f71806",
   "metadata": {},
   "source": [
    "## Reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7b6b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a  local model or any of the QA models on\n",
    "# Hugging Face's model hub (https://huggingface.co/models)\n",
    "# reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)\n",
    "# OR\n",
    "# use Transformer models\n",
    "DisBERT_SQD_MODEL = \"distilbert-base-uncased-distilled-squad\"\n",
    "T5_L_SQD_MODEL = \"/data/t5-large\"\n",
    "ROBERTA_BASE_MODEL = \"deepset/roberta-base-squad2\"\n",
    "\n",
    "\n",
    "RoBERTa_squad_reader = TransformersReader(model_name_or_path=ROBERTA_BASE_MODEL, \n",
    "                                          tokenizer=ROBERTA_BASE_MODEL, \n",
    "                                          use_gpu=True)\n",
    "# distBert_squad_reader = TransformersReader(model_name_or_path=DisBERT_SQD_MODEL, \n",
    "#                                            tokenizer=DisBERT_SQD_MODEL, \n",
    "#                                            use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53338a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = RoBERTa_squad_reader.predict(query, \n",
    "                                   documents=tfidf_ret.retrieve(query, top_k=5),\n",
    "                                   top_k=3)\n",
    "\n",
    "pprint(ans.get('answers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ebdf14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "045f5253",
   "metadata": {},
   "source": [
    "## Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a936dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is streaming data?\"\n",
    "query1 = \"How is deep learning used in industry?\"\n",
    "query2 = \"What is a data mesh?\"\n",
    "query3 = \"What do data scientists work on?\"\n",
    "query4 = \"How can cloud storage costs be reduced?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d7730b",
   "metadata": {},
   "source": [
    "**tfidf retriever:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ebdb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = ExtractiveQAPipeline(RoBERTa_squad_reader, tfidf_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a323fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pipe1.run(\n",
    "    query=query3, \n",
    "    params={\"Retriever\": {\"top_k\": 5}, \"Reader\": {\"top_k\": 3}}\n",
    ")\n",
    "\n",
    "(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99beceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...or use a util to simplify the output\n",
    "# Change `minimum` to `medium` or `all` to control the level of detail\n",
    "\n",
    "# print_answers(prediction, details=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1873c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe87a5a0",
   "metadata": {},
   "source": [
    "**embeddings retriever:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb37372",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = ExtractiveQAPipeline(RoBERTa_squad_reader, embedd_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adc2a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pipe2.run(\n",
    "    query=query3, \n",
    "    params={\"Retriever\": {\"top_k\": 5}, \"Reader\": {\"top_k\": 3}}\n",
    ")\n",
    "\n",
    "(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3687cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...or use a util to simplify the output\n",
    "# Change `minimum` to `medium` or `all` to control the level of detail\n",
    "\n",
    "# print_answers(prediction, details=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f76d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b550345f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
